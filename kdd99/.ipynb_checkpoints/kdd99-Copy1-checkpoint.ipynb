{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seem for reproducibility\n",
    "manualSeed = 2019\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "dataset = load_obj('kdd99')\n",
    "x_train = dataset['x_train']\n",
    "y_train = dataset['y_train']\n",
    "x_valid = dataset['x_valid']\n",
    "y_valid = dataset['y_valid']\n",
    "x_test = dataset['x_test']\n",
    "y_test = dataset['y_test']\n",
    "\n",
    "x_train = torch.tensor(x_train, device=device)\n",
    "# y_train = torch.tensor(y_train, device=device)\n",
    "x_valid = torch.tensor(x_valid, device=device)\n",
    "# y_valid = torch.tensor(y_valid, device=device)\n",
    "x_test = torch.tensor(x_test, device=device)\n",
    "# y_test = torch.tensor(y_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - define hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_D_num = 10\n",
    "G_group = {}\n",
    "D_group = {}\n",
    "z_avg = 0\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 100\n",
    "LR_G = 0.01  # learning rate for generator\n",
    "LR_D = 0.01  # learning rate for discriminator\n",
    "random_neuron = 100  # number of neurons as input of generator\n",
    "components = 121  # total number of points that G generated\n",
    "critic_num = 5\n",
    "D_loss_history = []\n",
    "G_loss_history = []\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - define network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(random_neuron, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, components)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(components, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 4/100 [02:17<54:59, 34.37s/it]"
     ]
    }
   ],
   "source": [
    "for iter in range(G_D_num):\n",
    "\n",
    "    begin = time()\n",
    "\n",
    "    D = Discriminator(ngpu).to(device)\n",
    "    G = Generator(ngpu).to(device)\n",
    "\n",
    "    # optimization\n",
    "    opt_D = torch.optim.Adam(D.parameters(), lr=LR_D)\n",
    "    opt_G = torch.optim.Adam(G.parameters(), lr=LR_G)\n",
    "\n",
    "    for step in tqdm(range(EPOCH)):\n",
    "        \n",
    "        for batch_iter in range(x_train.shape[0] // BATCH_SIZE):\n",
    "            \n",
    "            selected_real = x_train[batch_iter * BATCH_SIZE:(batch_iter * BATCH_SIZE + BATCH_SIZE)].float()\n",
    "            for _ in range(critic_num):\n",
    "\n",
    "                # random samples of real data\n",
    "#                 idx = np.random.choice(len(x_train), BATCH_SIZE)\n",
    "#                 selected_real = x_train[idx].float()\n",
    "\n",
    "                # random noises\n",
    "                G_noise = torch.randn(BATCH_SIZE, random_neuron).cuda()\n",
    "                G_data = G(G_noise)\n",
    "\n",
    "                prob_real = D(selected_real)  # D try to increase this prob\n",
    "                prob_fake = D(G_data)  # D try to decrease this prob\n",
    "\n",
    "                D_loss = -torch.mean(\n",
    "                    torch.log(prob_real + 1e-9) + torch.log(1. - prob_fake + 1e-9))\n",
    "                G_loss = torch.mean(torch.log(1. - prob_fake + 1e-9))\n",
    "\n",
    "                opt_D.zero_grad()\n",
    "                D_loss.backward(retain_graph=True)  # reusing computational graph\n",
    "                opt_D.step()\n",
    "\n",
    "            opt_G.zero_grad()\n",
    "            G_loss.backward()\n",
    "            opt_G.step()\n",
    "\n",
    "    end = time()\n",
    "    print(\n",
    "        str(iter + 1) + '/' + str(G_D_num) +\n",
    "        ' is done! Time is {0:0.2f} seconds;'.format((end - begin)))\n",
    "\n",
    "    prediction = D(x_test.float()).cpu().detach().numpy()\n",
    "    tmp_score = np.zeros_like(prediction)\n",
    "    for i in range(prediction.shape[0]):\n",
    "        if prediction[i] > alpha:\n",
    "            tmp_score[i] = 0\n",
    "        else:\n",
    "            tmp_score[i] = 1\n",
    "\n",
    "    precision = average_precision_score(y_test.reshape([-1, 1]), tmp_score)\n",
    "    recall = recall_score(y_test.reshape([-1, 1]), tmp_score)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print('Precision score: {0:0.2f}'.format(precision))\n",
    "    print('Recall score: {0:0.2f}'.format(recall))\n",
    "    print('F1 score: {0:0.2f}'.format(F1))\n",
    "    print('*************************************************************')\n",
    "\n",
    "    G_group['G' + str(iter)] = G\n",
    "    D_group['D' + str(iter)] = D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_score = 0.0\n",
    "for iter in range(G_D_num):\n",
    "    prediction = D_group['D' + str(iter)](x_test.float()).cpu().detach().numpy()\n",
    "    test_score = test_score + prediction / G_D_num\n",
    "\n",
    "for i in range(test_score.shape[0]):\n",
    "    if test_score[i] > alpha:\n",
    "        test_score[i] = 0\n",
    "    else:\n",
    "        test_score[i] = 1\n",
    "\n",
    "precision = average_precision_score(y_test.reshape([-1,1]), test_score)\n",
    "recall = recall_score(y_test.reshape([-1,1]), test_score)\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print('Precision score: {0:0.2f}'.format(precision))\n",
    "print('Recall score: {0:0.2f}'.format(recall))\n",
    "print('F1 score: {0:0.2f}'.format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
